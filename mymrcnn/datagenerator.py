
import os
import random
import datetime
import re
import math
import logging
from collections import OrderedDict
import multiprocessing
import numpy as np
import tensorflow as tf
from mymrcnn import utils
import cv2
# def mold_image(images, config):
#     """Expects an RGB image (or array of images) and subtracts
#     the mean pixel and converts it to float. Expects image
#     colors in RGB order.
#     """
#     return images.astype(np.float32) - config.MEAN_PIXEL


def unmold_image(normalized_images, config):
    """Takes a image normalized with mold() and returns the original."""
    return (normalized_images + config.MEAN_PIXEL).astype(np.uint8)

def mold_image(images, config):
    """Expects an RGB image (or array of images) and subtracts
    the mean pixel and converts it to float. Expects image
    colors in RGB order.
    """
    return images.astype(np.float32) - np.mean(images,axis=(0,1))

# # def unmold_image(normalized_images, config):
# #     """Takes a image normalized with mold() and returns the original."""
# #     return (normalized_images * 255).astype(np.uint8)

def load_image_gt(dataset, config, image_id, augment=False, augmentation=None,
                  use_mini_mask=False):
    """Load and return ground truth data for an image (image, mask, bounding boxes).

    augment: (deprecated. Use augmentation instead). If true, apply random
        image augmentation. Currently, only horizontal flipping is offered.
    augmentation: Optional. An imgaug (https://github.com/aleju/imgaug) augmentation.
        For example, passing imgaug.augmenters.Fliplr(0.5) flips images
        right/left 50% of the time.
    use_mini_mask: If False, returns full-size masks that are the same height
        and width as the original image. These can be big, for example
        1024x1024x100 (for 100 instances). Mini masks are smaller, typically,
        224x224 and are generated by extracting the bounding box of the
        object and resizing it to MINI_MASK_SHAPE.

    Returns:
    image: [height, width, 3]
    shape: the original shape of the image before resizing and cropping.
    class_ids: [instance_count] Integer class IDs
    bbox: [instance_count, (y1, x1, y2, x2)]
    mask: [height, width, instance_count]. The height and width are those
        of the image unless use_mini_mask is True, in which case they are
        defined in MINI_MASK_SHAPE.
    """
    # Load image and mask
    image = dataset.load_image(image_id)
    mask, _ = dataset.load_mask(image_id)
    original_shape = image.shape
    image = cv2.resize(image,(config.IMAGE_MAX_DIM,config.IMAGE_MIN_DIM),interpolation=cv2.INTER_LINEAR)
    # mask = cv2.resize(mask,(36,24),interpolation=cv2.INTER_NEAREST)
    # mask = mask[:,:,[0]]
    # Random horizontal flips.
    # TODO: will be removed in a future update in favor of augmentation
    if augment:
        logging.warning("'augment' is deprecated. Use 'augmentation' instead.")
        if random.randint(0, 1):
            image = np.fliplr(image)
            mask = np.fliplr(mask)

    # Augmentation
    # This requires the imgaug lib (https://github.com/aleju/imgaug)
    if augmentation:
        import imgaug

        # Augmenters that are safe to apply to masks
        # Some, such as Affine, have settings that make them unsafe, so always
        # test your augmentation on masks
        MASK_AUGMENTERS = ["Fliplr", "Flipud"]
        # ["Sequential", "SomeOf", "OneOf", "Sometimes",
        #                    "Fliplr", "Flipud", "CropAndPad"],
        #                    "Affine", "PiecewiseAffine"]

        def hook(images, augmenter, parents, default):
            """Determines which augmenters to apply to masks."""
            return augmenter.__class__.__name__ in MASK_AUGMENTERS

        # Store shapes before augmentation to compare
        image_shape = image.shape
        mask_shape = mask.shape
        # Make augmenters deterministic to apply similarly to images and masks
        det = augmentation.to_deterministic()
        image = det.augment_image(image)
        # Change mask to np.uint8 because imgaug doesn't support np.bool
        mask = det.augment_image(mask.astype(np.uint8),
                                 hooks=imgaug.HooksImages(activator=hook))
        # Verify that shapes didn't change
        assert image.shape == image_shape, "Augmentation shouldn't change image size"
        assert mask.shape == mask_shape, "Augmentation shouldn't change mask size"
        # Change mask back to bool
        mask = mask.astype(np.bool)
    return image, None, mask




def data_generator(dataset, config, shuffle=True, augment=False, augmentation=None,
                   random_rois=0, batch_size=1, detection_targets=False,
                   no_augmentation_sources=None):
    """A generator that returns images and corresponding target class ids,
    bounding box deltas, and masks.

    dataset: The Dataset object to pick data from
    config: The model config object
    shuffle: If True, shuffles the samples before every epoch
    augment: (deprecated. Use augmentation instead). If true, apply random
        image augmentation. Currently, only horizontal flipping is offered.
    augmentation: Optional. An imgaug (https://github.com/aleju/imgaug) augmentation.
        For example, passing imgaug.augmenters.Fliplr(0.5) flips images
        right/left 50% of the time.
    random_rois: If > 0 then generate proposals to be used to train the
                 network classifier and mask heads. Useful if training
                 the Mask RCNN part without the RPN.
    batch_size: How many images to return in each call
    detection_targets: If True, generate detection targets (class IDs, bbox
        deltas, and masks). Typically for debugging or visualizations because
        in trainig detection targets are generated by DetectionTargetLayer.
    no_augmentation_sources: Optional. List of sources to exclude for
        augmentation. A source is string that identifies a dataset and is
        defined in the Dataset class.

    Returns a Python generator. Upon calling next() on it, the
    generator returns two lists, inputs and outputs. The contents
    of the lists differs depending on the received arguments:
    inputs list:
    - images: [batch, H, W, C]
    - image_meta: [batch, (meta data)] Image details. See compose_image_meta()
    - rpn_match: [batch, N] Integer (1=positive anchor, -1=negative, 0=neutral)
    - rpn_bbox: [batch, N, (dy, dx, log(dh), log(dw))] Anchor bbox deltas.
    - gt_class_ids: [batch, MAX_GT_INSTANCES] Integer class IDs
    - gt_boxes: [batch, MAX_GT_INSTANCES, (y1, x1, y2, x2)]
    - gt_masks: [batch, height, width, MAX_GT_INSTANCES]. The height and width
                are those of the image unless use_mini_mask is True, in which
                case they are defined in MINI_MASK_SHAPE.

    outputs list: Usually empty in regular training. But if detection_targets
        is True then the outputs list contains target class_ids, bbox deltas,
        and masks.
    """
    b = 0  # batch item index
    image_index = -1
    image_ids = np.copy(dataset._image_ids)
    error_count = 0
    no_augmentation_sources = no_augmentation_sources or []
    

    # Keras requires a generator to run indefinitely.
    while True:
        try:
            # Increment index to pick next image. Shuffle if at the start of an epoch.
            image_index = (image_index + 1) % len(image_ids)
            if shuffle and image_index == 0:
                np.random.shuffle(image_ids)
            image_id = image_ids[image_index]

            # If the image source is not to be augmented pass None as augmentation
            if image_id in no_augmentation_sources:
                image, _, gt_masks = \
                load_image_gt(dataset, config, image_id, augment=augment,
                              augmentation=None,
                              use_mini_mask=config.USE_MINI_MASK)
            else:
                image, _, gt_masks = \
                    load_image_gt(dataset, config, image_id, augment=augment,
                                augmentation=augmentation,
                                use_mini_mask=config.USE_MINI_MASK)

            # Init batch arrays
            if b == 0:
                batch_images = np.zeros(
                    (batch_size,) + image.shape, dtype=np.float32)
                # batch_gt_class_ids = np.zeros(
                #     (batch_size, config.NUM_CLASSES), dtype=np.int32)
                batch_gt_masks = np.zeros(
                    (batch_size, gt_masks.shape[0], gt_masks.shape[1], \
                     config.NUM_CLASSES), dtype=gt_masks.dtype)
                    #  1), dtype=gt_masks.dtype)

            # Add to batch
            batch_images[b] = mold_image(image.astype(np.float32), config)
            # batch_gt_class_ids[b, :gt_class_ids.shape[0]] = gt_class_ids
            batch_gt_masks[b, :, :,:] = gt_masks

            b += 1

            # Batch full?
            if b >= batch_size:
                inputs = [batch_images,batch_gt_masks]
                outputs = []
                yield inputs, outputs

                # start a new batch
                b = 0
        except (GeneratorExit, KeyboardInterrupt):
            raise
        except:
            # Log it and skip the image
            logging.exception("Error processing image {}".format(
                dataset.image_info[image_id]))
            error_count += 1
            if error_count > 5:
                raise


# def testDataSet():
#     DataSetFact = ImageDataTrainningFactory("D:/MyWork")
#     DataSetFact.preload_images()
#     trainingSet,valSet = DataSetFact.getDataSet()
#     img_my_img1 = trainingSet.load_image("00a0954")
#     msk_my_mask1 = trainingSet.load_mask("00a0954")
#     img_my_img2 = valSet.load_image("00a0954")
#     msk_my_mask2 = valSet.load_mask("00a0954")
#     mask_1 = msk_my_mask1[0][:,:,0] * 255
#     mask_2 = msk_my_mask1[0][:,:,1] * 255
#     mask_1_2 =  msk_my_mask2[0][:,:,0] * 255
#     mask_2_2 = msk_my_mask2[0][:,:,1] * 255
#     print(len(trainingSet._image_ids))
#     print(len(valSet._image_ids))
#     cv2.imwrite("D:/MyWork/test_read1.png",img_my_img1)
#     cv2.imwrite("D:/MyWork/test_read2.png",img_my_img2)
#     cv2.imwrite("D:/MyWork/msk_G1.png",mask_1)
#     cv2.imwrite("D:/MyWork/msg_S1.png",mask_2)
#     cv2.imwrite("D:/MyWork/msk_G2.png",mask_1_2)
#     cv2.imwrite("D:/MyWork/msg_S2.png",mask_2_2)
# def testload_img_get():
#     DataSetFact = ImageDataSet.ImageDataTrainningFactory("D:/MyWork")
#     DataSetFact.preload_images()
#     trainingSet,valSet = DataSetFact.getDataSet()
#     config = cfg.Config()
#     config.NAME = "MyMRCNN_Model"
#     config.display()        
#     image, gt_class_ids, gt_masks = load_image_gt(trainingSet, config,"00a0954",use_mini_mask=True)
#     cv2.imwrite("D:/MyWork/msg_S1_load_gy.png",image)
#     print("asfs",np.shape(gt_masks))
#     cv2.imwrite("D:/MyWork/msg_S1_load_gt2.png",gt_masks[:,:,0] * 255)
# #     cv2.imwrite("D:/MyWork/msk_G2.png",mask_1_2)
# #     cv2.imwrite("D:/MyWork/msg_S2.png",mask_2_2)
#     print('hehe',gt_class_ids)
# testload_img_get()